##  kafka入门
kafka是由Linkedin公司开发的一个分布式(distributed)，多分区(partition)，多副本(replica)基于zookeeper协调的分布式消息系统。Linkedin在2010年贡献给了Apache基金会并成为顶级开源项目。如今Apache官方把它称作是A distributed streaming platform。主要用来构建实时数据流和流应用。
## 特点
* 发布&订阅
    * 像一个消息系统一样的进行读取和写入流式数据
* 处理
    * 编写可扩展的流处理应用处理实时处理的中的事件
* 存储
    * 在一个分布式，多副本，容错性的集群上非常安全的存储流式数据

## 设计原理
    * NIO
    * Zero Copy
    * 磁盘顺序读写
    * Queue数据结构
## Quickstart
### Step 1: Download the code
[Download](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.12-2.3.0.tgz) the 2.3.0 release and un-tar it.
 > `tar -xzf kafka_2.12-2.3.0.tgz`
 
 > `cd kafka_2.12-2.3.0`

### Step 2: Start the server
kafka使用zookeeper来进行协调管理，因此首先需要启动zookeeper服务，启动单个节点的zookeeper instance
 
 > `bin/zookeeper-server-start.sh config/zookeeper.properties`
 
 再启动kafka server
 > `bin/kafka-server-start.sh config/server.properties`

### Step 3: Create a topic
创建一个名字为test的topic，包含一个分区和一个副本
  >  `bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test`

然后可以查看集群上的topic列表
  > `bin/kafka-topics.sh --list --bootstrap-server localhost:9092`

### Step 4: Send some messages
kafka通过客户端的命令行可以将一个文件的内容或者标准的输入内容发送到kafka集群，默认的每一行都会作为一个单独的消息

> `bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test`

### Step 5: Start a consumer
kafka也能通过一个消费的命令行从集群消费消息到标准输出
  > `bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning`

### Step 6: Setting up a multi-broker cluster
扩展我们的集群节点(broker)到三个节点
> `cp config/server.properties config/server-1.properties`

> `cp config/server.properties config/server-2.properties`

编辑三个broker配置的文件
```python
config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dirs=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dirs=/tmp/kafka-logs-2
```
broker.id属性是集群上每一个broker节点上的唯一值和永久的名称

同样的也需要扩展到三个zookeeper节点

> `bin/kafka-server-start.sh config/server-1.properties &`

> `bin/kafka-server-start.sh config/server-2.properties &`

创建一个新的topic有三个副本

> `bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1 --topic my-replicated-topic`

采用describe topics命令查看每一个broker上的运行情况
> `bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-replicated-topic`

```python
    Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: 0    Leader: 1   Replicas: 1,2,0 Isr: 1,2,0
```